/*
 * Author: Kaiqiang Huang
 * Student Number: D14122793
 * programming code: DT228/A
 * Stream: Data Analytics
 * */
package MapReduce;

import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;

/*Drive class for all map-reduce process*/
public class wikiDrive extends Configured implements Tool {

	/*main method*/
    public static void main(String[] args) throws Exception {
    	int result = ToolRunner.run(new Configuration(), new wikiDrive(), args);
        System.exit(result);
    }

    @Override
    /*Override the method of run*/
    public int run(String[] args) throws Exception {

    	/*Make sure that the number of parameter is 5*/
        if (args.length != 5) {
        	/*Print message for command line if it is incorrect*/
            System.err.println("Usage: <input_path> <first_snippet> <output1> <second_snippet> <output2>");
            System.exit(-1);
        }

        /*First Job begins*/
        /*count total request*/
        /*Create new job*/
        Job RequestCount = Job.getInstance();
        /*Specify the class which will be called o run the job*/
        RequestCount.setJarByClass(wikiDrive.class);
        /*set up Job name*/
        RequestCount.setJobName("RequestCount");
        /*Call first mapper and reducer*/
        RequestCount.setMapperClass(FirstTaskMapper.class);
        RequestCount.setReducerClass(FirstTaskReducer.class);
        /*Specify the types for reducer output key and value*/
        RequestCount.setOutputKeyClass(Text.class);
        RequestCount.setOutputValueClass(LongWritable.class);
        /*Specify the input directory and output directory*/
        FileInputFormat.addInputPath(RequestCount, new Path(args[0]));
        FileOutputFormat.setOutputPath(RequestCount, new Path(args[1]));
        RequestCount.waitForCompletion(true);
        /*First Job ends*/

        /*Second Job begins*/
        /*Sort output by descending order*/
        /*Create new job*/
        Job firstOrder = Job.getInstance();
        firstOrder.setJarByClass(wikiDrive.class);
        firstOrder.setJobName("firstOrder");
        /*Call the first Mapper*/
        firstOrder.setMapperClass(FirstTaskOrderMapper.class);
        /*Call the first reducer*/
        firstOrder.setReducerClass(FirstTaskOrderReducer.class);
        /*Call the method of sorting*/
        firstOrder.setSortComparatorClass(FirstTaskOrderMethod.class);
        /*Specify the format of the intermediate output key and values generated by Mapper*/
        firstOrder.setMapOutputKeyClass(LongWritable.class);
        firstOrder.setMapOutputValueClass(Text.class);
        /*Specify the types for reducer output key and value*/
        firstOrder.setOutputKeyClass(Text.class);
        firstOrder.setOutputValueClass(LongWritable.class);
        /*Specify the input directory and output directory*/
        FileInputFormat.addInputPath(firstOrder, new Path(args[1]));
        FileOutputFormat.setOutputPath(firstOrder, new Path(args[2]));
        firstOrder.waitForCompletion(true);
        /*Second Job ends*/

        /*Third Job begins*/
        /*Calculate the average number of request by language*/
        /*create new job*/
        Job Average = Job.getInstance();
        Average.setJarByClass(wikiDrive.class);
        Average.setJobName("Average");
        /*Call the second mapper, reducer and sorting method*/
        Average.setMapperClass(SecondTaskMapper.class);
        Average.setReducerClass(SecondTaskReducer.class);
        /*Specify the format of the intermediate output key and values generated by Mapper*/
        Average.setMapOutputKeyClass(Text.class);
        Average.setMapOutputValueClass(LongWritable.class);
        /*Specify the types for reducer output key and value*/
        Average.setOutputKeyClass(Text.class);
        Average.setOutputValueClass(DoubleWritable.class);
        /*Specify the input directory and output directory*/
        FileInputFormat.addInputPath(Average, new Path(args[1]));
        FileOutputFormat.setOutputPath(Average, new Path(args[3]));
        Average.waitForCompletion(true);
        /*Third Job ends*/
        
        /*Forth Job begins*/
        /*Sort the output by descending sorting*/
        /*create new job*/
        Job secondCount = Job.getInstance();
        secondCount.setJarByClass(wikiDrive.class);
        secondCount.setJobName("secondCount");
        /*Call the second sorting mapper, reducer and sorting method*/
        secondCount.setMapperClass(SecondTaskOrderMapper.class);
        secondCount.setReducerClass(SecondTaskOrderReducer.class);
        /*Specify the method of sorting*/
        secondCount.setSortComparatorClass(SecondTaskOrderMethod.class);
        /*Specify the format of the intermediate output key and values generated by Mapper*/
        secondCount.setMapOutputKeyClass(DoubleWritable.class);
        secondCount.setMapOutputValueClass(Text.class);
        /*Specify the types for reducer output key and value*/
        secondCount.setOutputKeyClass(Text.class);
        secondCount.setOutputValueClass(DoubleWritable.class);
        /*Specify the input directory and output directory*/
        FileInputFormat.addInputPath(secondCount, new Path(args[3]));
        FileOutputFormat.setOutputPath(secondCount, new Path(args[4]));
        secondCount.waitForCompletion(true);
		return 0;
    }
}